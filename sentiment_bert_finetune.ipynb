{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab645a-bfbc-48ca-bbb4-ee0611a6f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Declaration\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.optim import AdamW \n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c326b-d4c2-4999-8bc9-45f1239807b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "system settings\n",
    "\"\"\"\n",
    "def set_overall_seed(seed=16):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_overall_seed(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230baeed-0892-4922-8cd8-54e9cde7f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define a class for importing Dataset\n",
    "\"\"\"\n",
    "class ProcessedIMDbDataset(Dataset):\n",
    "    \"\"\"loaded processed dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, sequences, attention_masks, labels, lengths=None):\n",
    "        self.sequences = sequences\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "        self.lengths = lengths if lengths is not None else torch.ones_like(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.sequences[idx],\n",
    "            'attention_mask': self.attention_masks[idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'lengths': self.lengths[idx]\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc19cc-044e-41c5-936c-d01a0702ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Trainer based on Bert Finetuning\n",
    "\"\"\"\n",
    "class BertSentimentTrainer:\n",
    "    \"\"\" SentimentAnalyzer Based on Bert \"\"\"\n",
    "    def __init__(self, model_name='bert-base-uncased', num_labels=2, max_length=512):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f'using device {self.device}')\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=num_labels)\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.test_loader = None\n",
    "\n",
    "\n",
    "    def load_data(self, file_path='./all_data.pt', batch_size=20):\n",
    "        print(f\"loading dataset\")\n",
    "\n",
    "        data = torch.load(file_path, weights_only=True)\n",
    "\n",
    "        train_dataset = ProcessedIMDbDataset(\n",
    "            data['train_sequences'],\n",
    "            data['train_masks'], \n",
    "            data['train_labels'],\n",
    "            data['train_lengths']\n",
    "        )\n",
    "        \n",
    "        val_dataset = ProcessedIMDbDataset(\n",
    "            data['val_sequences'],\n",
    "            data['val_masks'],\n",
    "            data['val_labels'], \n",
    "            data['val_lengths']\n",
    "        )\n",
    "        \n",
    "        test_dataset = ProcessedIMDbDataset(\n",
    "            data['test_sequences'],\n",
    "            data['test_masks'],\n",
    "            data['test_labels'],\n",
    "            data['test_lengths']\n",
    "        )\n",
    "\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        print(f\"loaded done, train dataset:{len(train_dataset)}, val_dataset:{len(val_dataset)}, test_dataset:{len(test_dataset)}\")\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "    def train(self, epochs=4, learning_rate=2e-5, warmup_steps=0, logging_steps=50):\n",
    "        if self.train_loader is None or self.val_loader is None:\n",
    "            raise ValueError(\"datasets not ready!\")\n",
    "\n",
    "        # use AdamW\n",
    "        optimizer = AdamW(self.model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "        total_steps = len(self.train_loader) * epochs\n",
    "\n",
    "        # scheduler for learning rates, with warmup\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        training_stats = []\n",
    "        best_val_accuracy = 0\n",
    "        patience = 2\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch+1}/epochs\")\n",
    "            print(\"=\" * 80)\n",
    "\n",
    "            self.model.train()\n",
    "            total_train_loss = 0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "\n",
    "            batch_progress = tqdm(self.train_loader, desc='training')\n",
    "            for step, batch in enumerate(batch_progress):\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                train_correct += (predictions == labels).sum().item()\n",
    "                train_total += labels.size(0)\n",
    "\n",
    "                if step % logging_steps == 0:\n",
    "                    batch_progress.set_postfix(\n",
    "                        {\n",
    "                        'loss': f\"{loss.item():.4f}\",\n",
    "                        'acc': f\"{train_correct/train_total:.4f}\"\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                avg_train_loss = total_train_loss / len(self.train_loader)\n",
    "                train_accuracy = train_correct / train_total\n",
    "                val_accuracy, val_loss = self.evaluate(self.val_loader)\n",
    "                print(f\"training loss: {avg_train_loss:.4f}, training accuracy:{train_accuracy:.4f}\")\n",
    "\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    self.save_model('best_bert_model')\n",
    "                    patience_count = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"early stop\")\n",
    "                    break\n",
    "\n",
    "                training_stats.append(\n",
    "                    {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'train_loss': avg_train_loss,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_accuracy\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # at last, we load the best performance model, for further process\n",
    "        self.load_model('best_bert_model')\n",
    "        return training_stats\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=\"evaluating\"):\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        return accuracy, avg_loss\n",
    "\n",
    "    def predict(self, texts):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for text in texts:\n",
    "                encoding = self.tokenizer(\n",
    "                    text,\n",
    "                    truncation=True,\n",
    "                    padding='max_length',\n",
    "                    max_length=self.max_length,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                input_ids = encoding['input_ids'].to(self.device)\n",
    "                attention_mask = encoding['attention_mask'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                pred = torch.argmax(logits, dim=1)\n",
    "                \n",
    "                predictions.append(pred.cpu().item())\n",
    "                probabilities.append(probs.cpu().numpy())\n",
    "\n",
    "        return predictions, probabilities\n",
    "\n",
    "    def overall_evaluation(self):\n",
    "        if self.test_loader is None:\n",
    "            raise ValueError(\"test datasets not ready\")\n",
    "    \n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        all_probabilities = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.test_loader, desc=\"training\"):\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probabilities = torch.softmax(logits, dim=1)\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                \n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probabilities.extend(probabilities.cpu().numpy())\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        class_report = classification_report(all_labels, all_predictions, target_names=['negtive', 'positive'])\n",
    "        conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'classification_report': class_report,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'predictions': all_predictions,\n",
    "            'probabilities': all_probabilities\n",
    "        }\n",
    "        \n",
    "        print(f\"test accuracy{accuracy:.4f}\")\n",
    "        print(f\"F1 score: {f1:.4f}\")\n",
    "        print(\"\\n class report:\")\n",
    "        print(class_report)\n",
    "        print(\"\\n confusion matrix\")\n",
    "        print(conf_matrix)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def save_model(self, path):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    \n",
    "        self.model.save_pretrained(path)\n",
    "        self.tokenizer.save_pretrained(path)\n",
    "        print(f\"save model to: {path}\")\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"model file not exist!\")\n",
    "            return\n",
    "        \n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "        self.model.to(self.device)\n",
    "        print(f\"loaded model from {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce72e4-b266-444f-89dc-1f4e057e4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualization Part\n",
    "\"\"\"\n",
    "\n",
    "def plt_training_history_data(training_stats):\n",
    "    \"\"\"\n",
    "    use matplotlib to plot training history\n",
    "    \"\"\"\n",
    "\n",
    "    df_stats = pd.DataFrame(training_stats)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # loss\n",
    "    ax1.plot(df_stats['epoch'], df_stats['train_loss'], 'b-', label='training loss')\n",
    "    ax1.plot(df_stats['epoch'], df_stats['val_loss'], 'r-', label='validation loss')\n",
    "    ax1.set_title('training and validation loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # accuracy\n",
    "    ax2.plot(df_stats['epoch'], df_stats['train_accuracy'], 'b-', label='training accuracy')\n",
    "    ax2.plot(df_stats['epoch'], df_stats['val_accuracy'], 'r-', label='val accuracy')\n",
    "    ax2.set_title('taining and validation accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bert_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_names=['negtive', 'positive']):\n",
    "    \"\"\"plot confusion matrix\"\"\"\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('BERT Finetuned Confusion')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.savefig('bert_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d388b-79df-4eb6-82b1-d93a672dd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare Performance with previous LSTM Model\n",
    "\"\"\"\n",
    "def compare_with_lstm(bert_results, lstm_results):\n",
    "    bert_accuracy = bert_results['accuracy']\n",
    "    bert_f1 = bert_results['f1_score']\n",
    "    print(f\"BERT Model:\")\n",
    "    print(f\"  Accuracy: {bert_accuracy:.4f}\")\n",
    "    print(f\"  F1 Score: {bert_f1:.4f}\")\n",
    "\n",
    "    lstm_accuracy = lstm_results.get('accuracy', 0)\n",
    "    lstm_f1 = lstm_results.get('f1_score', 0)\n",
    "    print(f\"LSTM Model:\")\n",
    "    print(f\"  Accuracy: {lstm_accuracy:.4f}\")\n",
    "    print(f\"  F1 Score: {lstm_f1:.4f}\")\n",
    "\n",
    "    accuracy_improve = (bert_accuracy - lstm_accuracy) / lstm_accuracy * 100\n",
    "    f1_improve = (bert_f1 - lstm_f1) / lstm_f1 * 100\n",
    "    print(f\"\\nPerformance Improve:\")\n",
    "    print(f\"  accuracy_improve: {accuracy_improve:.4f}%\")\n",
    "    print(f\"  f1_improve: {f1_improve:.4f}%\")\n",
    "\n",
    "def load_lstm_results(path):\n",
    "    lstm_results = None\n",
    "    \n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            lstm_results = json.load(f)\n",
    "    except e:\n",
    "        print(f\"load lstm results failed: {str(e)}\")\n",
    "\n",
    "    return lstm_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3ee93-3551-4ffa-b81a-81b67447eabb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Program Main Process\n",
    "\"\"\"\n",
    "def perform_training():\n",
    "    work_path = os.getcwd()\n",
    "    data_file = 'all_data.pt'\n",
    "    data_file_path = work_path + \"\\\\processed_data\\\\\" + data_file\n",
    "\n",
    "    trainer = BertSentimentTrainer(\n",
    "        model_name = 'bert-base-uncased',\n",
    "        num_labels=2,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    trainer.load_data(data_file_path, batch_size=8)\n",
    "\n",
    "    training_stats = trainer.train(\n",
    "        epochs=4,\n",
    "        learning_rate=2e-5,\n",
    "        warmup_steps=100,\n",
    "        logging_steps=10\n",
    "    )\n",
    "\n",
    "    results = trainer.overall_evaluation()\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_save_path = f\"sentiment_bert_finetune_model_{timestamp}\"\n",
    "    trainer.save_model(model_save_path)\n",
    "\n",
    "    return trainer, results, training_stats\n",
    "\n",
    "\n",
    "def test_texts(trainer):\n",
    "    test_samples = [\n",
    "        \"quite a good movie, but the ending could be better!\",\n",
    "        \"it's a fantastic film I've ever enjoyed!\"\n",
    "    ]\n",
    "\n",
    "    predictions, probabilities = trainer.predict(test_samples)\n",
    "\n",
    "    sentiment_mapping = {0 : 'negtive', 1 : 'positive'}\n",
    "\n",
    "    for text, pred, prob in zip(test_samples, predictions, probabilities):\n",
    "        print(f\"testing text: {text}\")\n",
    "        print(f\"prediction: {sentiment_mapping[pred]}, {max(prob):.4f}\")\n",
    "\n",
    "def main():\n",
    "    train = True\n",
    "    \n",
    "    if train:\n",
    "        trainer, bert_results, training_stats = perform_training()\n",
    "        plt_training_history_data(training_stats)\n",
    "        plot_confusion_matrix(bert_results['confusion_matrix'])\n",
    "\n",
    "        lstm_results = load_lstm_results(\"./lstm_results.json\")\n",
    "        compare_with_lstm(bert_results, lstm_results)\n",
    "    \n",
    "    test_texts(trainer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
